# HELP nv_inference_request_success Number of successful inference requests, all batch sizes
# TYPE nv_inference_request_success counter
nv_inference_request_success{model="ensemble",version="1"} 0.000000
nv_inference_request_success{model="stream",version="1"} 0.000000
nv_inference_request_success{model="stream_0",version="1"} 0.000000
nv_inference_request_success{model="test-model",version="1"} 0.000000
# HELP nv_inference_request_failure Number of failed inference requests, all batch sizes
# TYPE nv_inference_request_failure counter
nv_inference_request_failure{model="ensemble",version="1"} 0.000000
nv_inference_request_failure{model="stream",version="1"} 0.000000
nv_inference_request_failure{model="stream_0",version="1"} 0.000000
nv_inference_request_failure{model="test-model",version="1"} 0.000000
# HELP nv_inference_count Number of inferences performed (does not include cached requests)
# TYPE nv_inference_count counter
nv_inference_count{model="ensemble",version="1"} 0.000000
nv_inference_count{model="stream",version="1"} 0.000000
nv_inference_count{model="stream_0",version="1"} 0.000000
nv_inference_count{model="test-model",version="1"} 0.000000
# HELP nv_inference_exec_count Number of model executions performed (does not include cached requests)
# TYPE nv_inference_exec_count counter
nv_inference_exec_count{model="ensemble",version="1"} 0.000000
nv_inference_exec_count{model="stream",version="1"} 0.000000
nv_inference_exec_count{model="stream_0",version="1"} 0.000000
nv_inference_exec_count{model="test-model",version="1"} 0.000000
# HELP nv_inference_request_duration_us Cumulative inference request duration in microseconds (includes cached requests)
# TYPE nv_inference_request_duration_us counter
nv_inference_request_duration_us{model="ensemble",version="1"} 0.000000
nv_inference_request_duration_us{model="stream",version="1"} 0.000000
nv_inference_request_duration_us{model="stream_0",version="1"} 0.000000
nv_inference_request_duration_us{model="test-model",version="1"} 0.000000
# HELP nv_inference_queue_duration_us Cumulative inference queuing duration in microseconds (includes cached requests)
# TYPE nv_inference_queue_duration_us counter
nv_inference_queue_duration_us{model="ensemble",version="1"} 0.000000
nv_inference_queue_duration_us{model="stream",version="1"} 0.000000
nv_inference_queue_duration_us{model="stream_0",version="1"} 0.000000
nv_inference_queue_duration_us{model="test-model",version="1"} 0.000000
# HELP nv_inference_compute_input_duration_us Cumulative compute input duration in microseconds (does not include cached requests)
# TYPE nv_inference_compute_input_duration_us counter
nv_inference_compute_input_duration_us{model="ensemble",version="1"} 0.000000
nv_inference_compute_input_duration_us{model="stream",version="1"} 0.000000
nv_inference_compute_input_duration_us{model="stream_0",version="1"} 0.000000
nv_inference_compute_input_duration_us{model="test-model",version="1"} 0.000000
# HELP nv_inference_compute_infer_duration_us Cumulative compute inference duration in microseconds (does not include cached requests)
# TYPE nv_inference_compute_infer_duration_us counter
nv_inference_compute_infer_duration_us{model="ensemble",version="1"} 0.000000
nv_inference_compute_infer_duration_us{model="stream",version="1"} 0.000000
nv_inference_compute_infer_duration_us{model="stream_0",version="1"} 0.000000
nv_inference_compute_infer_duration_us{model="test-model",version="1"} 0.000000
# HELP nv_inference_compute_output_duration_us Cumulative inference compute output duration in microseconds (does not include cached requests)
# TYPE nv_inference_compute_output_duration_us counter
nv_inference_compute_output_duration_us{model="ensemble",version="1"} 0.000000
nv_inference_compute_output_duration_us{model="stream",version="1"} 0.000000
nv_inference_compute_output_duration_us{model="stream_0",version="1"} 0.000000
nv_inference_compute_output_duration_us{model="test-model",version="1"} 0.000000
# HELP nv_cache_num_entries Number of responses stored in response cache
# TYPE nv_cache_num_entries gauge
# HELP nv_cache_num_lookups Number of cache lookups in response cache
# TYPE nv_cache_num_lookups gauge
# HELP nv_cache_num_hits Number of cache hits in response cache
# TYPE nv_cache_num_hits gauge
# HELP nv_cache_num_misses Number of cache misses in response cache
# TYPE nv_cache_num_misses gauge
# HELP nv_cache_num_evictions Number of cache evictions in response cache
# TYPE nv_cache_num_evictions gauge
# HELP nv_cache_lookup_duration Total cache lookup duration (hit and miss), in microseconds
# TYPE nv_cache_lookup_duration gauge
# HELP nv_cache_util Cache utilization [0.0 - 1.0]
# TYPE nv_cache_util gauge
# HELP nv_cache_num_hits_per_model Number of cache hits per model
# TYPE nv_cache_num_hits_per_model counter
nv_cache_num_hits_per_model{model="ensemble",version="1"} 0.000000
nv_cache_num_hits_per_model{model="stream",version="1"} 0.000000
nv_cache_num_hits_per_model{model="stream_0",version="1"} 0.000000
nv_cache_num_hits_per_model{model="test-model",version="1"} 0.000000
# HELP nv_cache_hit_lookup_duration_per_model Total cache hit lookup duration per model, in microseconds
# TYPE nv_cache_hit_lookup_duration_per_model counter
nv_cache_hit_lookup_duration_per_model{model="ensemble",version="1"} 0.000000
nv_cache_hit_lookup_duration_per_model{model="stream",version="1"} 0.000000
nv_cache_hit_lookup_duration_per_model{model="stream_0",version="1"} 0.000000
nv_cache_hit_lookup_duration_per_model{model="test-model",version="1"} 0.000000
# HELP nv_gpu_utilization GPU utilization rate [0.0 - 1.0)
# TYPE nv_gpu_utilization gauge
nv_gpu_utilization{gpu_uuid="GPU-34e6b894-a1d9-004f-2f2d-6b79056c0d5d"} 0.000000
nv_gpu_utilization{gpu_uuid="GPU-921ea49e-d85d-185c-5679-b2aa45f32fa6"} 0.000000
# HELP nv_gpu_memory_total_bytes GPU total memory, in bytes
# TYPE nv_gpu_memory_total_bytes gauge
nv_gpu_memory_total_bytes{gpu_uuid="GPU-34e6b894-a1d9-004f-2f2d-6b79056c0d5d"} 17179869184.000000
nv_gpu_memory_total_bytes{gpu_uuid="GPU-921ea49e-d85d-185c-5679-b2aa45f32fa6"} 17179869184.000000
# HELP nv_gpu_memory_used_bytes GPU used memory, in bytes
# TYPE nv_gpu_memory_used_bytes gauge
nv_gpu_memory_used_bytes{gpu_uuid="GPU-34e6b894-a1d9-004f-2f2d-6b79056c0d5d"} 1579155456.000000
nv_gpu_memory_used_bytes{gpu_uuid="GPU-921ea49e-d85d-185c-5679-b2aa45f32fa6"} 1579155456.000000
# HELP nv_gpu_power_usage GPU power usage in watts
# TYPE nv_gpu_power_usage gauge
nv_gpu_power_usage{gpu_uuid="GPU-34e6b894-a1d9-004f-2f2d-6b79056c0d5d"} 54.686000
nv_gpu_power_usage{gpu_uuid="GPU-921ea49e-d85d-185c-5679-b2aa45f32fa6"} 57.063000
# HELP nv_gpu_power_limit GPU power management limit in watts
# TYPE nv_gpu_power_limit gauge
nv_gpu_power_limit{gpu_uuid="GPU-34e6b894-a1d9-004f-2f2d-6b79056c0d5d"} 300.000000
nv_gpu_power_limit{gpu_uuid="GPU-921ea49e-d85d-185c-5679-b2aa45f32fa6"} 300.000000
# HELP nv_energy_consumption GPU energy consumption in joules since the Triton Server started
# TYPE nv_energy_consumption counter
nv_energy_consumption{gpu_uuid="GPU-34e6b894-a1d9-004f-2f2d-6b79056c0d5d"} 5398.954000
nv_energy_consumption{gpu_uuid="GPU-921ea49e-d85d-185c-5679-b2aa45f32fa6"} 5636.370000
